#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
1C Help Parser - –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞
"""

import os
import sys
import argparse
import json
from datetime import datetime
from pathlib import Path

def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    try:
        import bs4
        print("‚úÖ BeautifulSoup4 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except ImportError:
        print("‚ùå BeautifulSoup4 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install beautifulsoup4")
        return False
    
    try:
        import lxml
        print("‚úÖ lxml —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except ImportError:
        print("‚ö†Ô∏è  lxml –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install lxml")
    
    return True

def cleanup_data():
    """–û—á–∏—â–∞–µ—Ç –Ω–µ–Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ data"""
    import glob
    
    files_to_remove = [
        "data/1c_summary.json",
        "data/context_chunks/",
        "data/hbk_analysis.json"
    ]
    
    print("üßπ –û—á–∏—Å—Ç–∫–∞ –Ω–µ–Ω—É–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    
    for pattern in files_to_remove:
        if pattern.endswith('/'):
            # –£–¥–∞–ª—è–µ–º –ø–∞–ø–∫—É
            if os.path.exists(pattern):
                import shutil
                shutil.rmtree(pattern)
                print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–∞ –ø–∞–ø–∫–∞: {pattern}")
        else:
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
            if os.path.exists(pattern):
                os.remove(pattern)
                print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª: {pattern}")
    
    print("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

def run_parser(zip_file, max_files=None, use_improved=True):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞"""
    print(f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {zip_file}")
    os.system(f"set PYTHONPATH=src && python src/parsers/hbk_parser.py {zip_file}")
    
    print(f"üìù –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞: {zip_file}")
    if max_files:
        os.system(f"set PYTHONPATH=src && python src/parsers/bsl_syntax_extractor.py {zip_file} --max-files {max_files}")
    else:
        os.system(f"set PYTHONPATH=src && python src/parsers/bsl_syntax_extractor.py {zip_file}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è JSON —Ñ–∞–π–ª–∞
    base_name = Path(zip_file).stem
    json_file = f"data/bsl_syntax_{base_name}.json" if "root" in base_name else "data/bsl_syntax.json"
    md_file = json_file.replace('.json', '.md')
    
    if os.path.exists(json_file):
        print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {json_file}")
        # –°–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã: JSON, TXT –∏ –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
        os.system(f"set PYTHONPATH=src && python src/converters/context_converter.py {json_file} json,txt,search_index")
        
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        if os.path.exists(json_file):
            os.remove(json_file)
            print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª: {json_file}")
        if os.path.exists(md_file):
            os.remove(md_file)
            print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª: {md_file}")
    else:
        print(f"‚ö†Ô∏è  –§–∞–π–ª {json_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")

def create_optimized_version():
    """–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –∏–∑ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç...")
    try:
        with open('data/1c_context.json', 'r', encoding='utf-8') as f:
            full_data = json.load(f)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(full_data['context_items'])} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª data/1c_context.json –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –ø–æ–ª–Ω—É—é –≤–µ—Ä—Å–∏—é: python run.py --full")
        return
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        return
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–≤—ã—Å–æ–∫–∏–π -> –Ω–∏–∑–∫–∏–π)
    priorities = {
        'methods': 1,      # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        'functions': 2,    # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        'operators': 3,    # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        'objects': 4,      # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        'properties': 5    # –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    }
    
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    limits = {
        'methods': 100,      # –í—Å–µ –º–µ—Ç–æ–¥—ã
        'functions': 100,    # –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏
        'operators': 20,     # –í—Å–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã
        'objects': 1000,     # –¢–æ–ø-1000 –æ–±—ä–µ–∫—Ç–æ–≤
        'properties': 20     # –¢–æ–ø-20 —Å–≤–æ–π—Å—Ç–≤
    }
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    categories = {}
    for item in full_data['context_items']:
        category = item['category']
        if category not in categories:
            categories[category] = []
        categories[category].append(item)
    
    print("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for category, items in categories.items():
        print(f"  {category}: {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
    sorted_categories = sorted(categories.keys(), key=lambda x: priorities.get(x, 999))
    
    optimized_items = []
    
    for category in sorted_categories:
        items = categories[category]
        limit = limits.get(category, 100)
        
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {category} (–ª–∏–º–∏—Ç: {limit} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        scored_items = []
        for item in items:
            score = 0
            
            # –ù–∞–ª–∏—á–∏–µ –º–µ—Ç–æ–¥–æ–≤ (–≤—ã—Å–æ–∫–∏–π –≤–µ—Å)
            if item['metadata'].get('methods'):
                score += len(item['metadata']['methods']) * 10
                
            # –ù–∞–ª–∏—á–∏–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ (—Å—Ä–µ–¥–Ω–∏–π –≤–µ—Å)
            if item['metadata'].get('syntax') or item['metadata'].get('syntax_variants'):
                score += 5
                
            # –ù–∞–ª–∏—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Å—Ä–µ–¥–Ω–∏–π –≤–µ—Å)
            if item['metadata'].get('parameters') or item['metadata'].get('parameters_by_variant'):
                score += 3
                
            # –ù–∞–ª–∏—á–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ (–Ω–∏–∑–∫–∏–π –≤–µ—Å)
            if item['metadata'].get('example'):
                score += 1
                
            # –ù–∞–ª–∏—á–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è (–±–∞–∑–æ–≤—ã–π –≤–µ—Å)
            if item['content']:
                score += 1
                
            scored_items.append((item, score))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–∞–∂–Ω–æ—Å—Ç–∏
        scored_items.sort(key=lambda x: x[1], reverse=True)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ø —ç–ª–µ–º–µ–Ω—Ç—ã
        top_items = [item for item, score in scored_items[:limit]]
        optimized_items.extend(top_items)
        
        print(f"  –í—ã–±—Ä–∞–Ω–æ {len(top_items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    optimized_data = {
        'metadata': {
            'source': '1C BSL Documentation (Optimized)',
            'generated_at': datetime.now().isoformat(),
            'total_items': len(optimized_items),
            'categories': list(set(item['category'] for item in optimized_items)),
            'optimization': '–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å –ª–∏–º–∏—Ç–∞–º–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º',
            'original_size': len(full_data['context_items']),
            'compression_ratio': f"{len(optimized_items) / len(full_data['context_items']) * 100:.1f}%"
        },
        'context_items': optimized_items
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
    output_file = 'data/1c_context_optimized.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(optimized_data, f, ensure_ascii=False, indent=2)
    
    print(f"\n=== –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ===")
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(full_data['context_items'])} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    print(f"–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(optimized_items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    print(f"–°—Ç–µ–ø–µ–Ω—å —Å–∂–∞—Ç–∏—è: {len(optimized_items) / len(full_data['context_items']) * 100:.1f}%")
    print(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–ª—Å—è
    if os.path.exists(output_file):
        file_size = os.path.getsize(output_file) / 1024 / 1024
        print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:.2f} MB")
    else:
        print("–û–®–ò–ë–ö–ê: –§–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–ª—Å—è!")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –≤–µ—Ä—Å–∏—é
    content = "# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ 1–° (BSL)\n\n"
    content += "–≠—Ç–æ—Ç —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å—É —è–∑—ã–∫–∞ 1–°:–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ.\n"
    content += "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤ 1–°.\n\n"
    content += "=" * 80 + "\n\n"
    
    for item in optimized_items:
        content += item['content']
        content += "\n\n" + "=" * 80 + "\n\n"
    
    txt_file = 'data/1c_context_optimized.txt'
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"–¢–µ–∫—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {txt_file}")

def run_demo(context_file):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é"""
    if "optimized" in context_file:
        print("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        print("–ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ–∏—Å–∫–∞...")
        os.system(f"set PYTHONPATH=src && python src/demos/optimized_demo.py {context_file} --examples")
    elif "root" in context_file:
        print("üåê –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–∞ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π)")
        os.system(f"set PYTHONPATH=src && python src/demos/test_root_demo.py {context_file}")
    else:
        print("üá∑üá∫ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (—Ä—É—Å—Å–∫–∏–π)")
        os.system(f"set PYTHONPATH=src && python src/demos/llm_context_demo.py {context_file}")

def main():
    parser = argparse.ArgumentParser(description="1C Help Parser - –ü–∞—Ä—Å–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ 1–°")
    parser.add_argument("--file", "-f", help="–ü—É—Ç—å –∫ ZIP —Ñ–∞–π–ª—É –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
    parser.add_argument("--demo", "-d", help="–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
    parser.add_argument("--check", "-c", action="store_true", help="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
    parser.add_argument("--auto", action="store_true", help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –±–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–≤–æ–¥–∞")
    parser.add_argument("--full", action="store_true", help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é (–≤—Å–µ —Ñ–∞–π–ª—ã)")
    parser.add_argument("--optimized", action="store_true", help="–°–æ–∑–¥–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã)")
    parser.add_argument("--basic", action="store_true", help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–∑–æ–≤—É—é –≤–µ—Ä—Å–∏—é –ø–∞—Ä—Å–µ—Ä–∞")
    
    args = parser.parse_args()
    
    print("üîß 1C Help Parser")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    if args.check:
        check_dependencies()
        return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if args.file:
        if not os.path.exists(args.file):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.file}")
            return
        
        use_improved = not args.basic
        run_parser(args.file, use_improved=use_improved)
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è
    elif args.demo:
        if not os.path.exists(args.demo):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.demo}")
            return
        
        run_demo(args.demo)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º
    elif args.auto:
        print("ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
        run_parser("data/rebuilt.shcntx_ru.zip")
    
    # –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    elif args.full:
        print("üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ - –≤—Å–µ —Ñ–∞–π–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
        run_parser("data/rebuilt.shcntx_ru.zip", max_files=None)
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
    elif args.optimized:
        print("üéØ –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏")
        create_optimized_version()
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
    else:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        check_dependencies()
        
        print("\nüéØ –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
        print("1. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é (shcntx_ru.zip) - –ø–µ—Ä–≤—ã–µ 500 —Ñ–∞–π–ª–æ–≤")
        print("2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é (shcntx_ru.zip) - –≤—Å–µ —Ñ–∞–π–ª—ã")
        print("3. –°–æ–∑–¥–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã)")
        print("4. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        print("5. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
        print("6. –û—á–∏—Å—Ç–∏—Ç—å –Ω–µ–Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã")
        print("0. –í—ã—Ö–æ–¥")
        
        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (0-6): ").strip()
        
        if choice == "1":
            run_parser("data/rebuilt.shcntx_ru.zip", max_files=500)
        elif choice == "2":
            run_parser("data/rebuilt.shcntx_ru.zip", max_files=None)
        elif choice == "3":
            print("üéØ –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏")
            create_optimized_version()
        elif choice == "4":
            run_demo("data/1c_context_optimized.json")
        elif choice == "5":
            print("‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –≤—ã—à–µ")
        elif choice == "6":
            cleanup_data()
        elif choice == "0":
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

if __name__ == "__main__":
    main() 